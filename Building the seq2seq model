//This section deals with the various functions that help us implement the seq2seq model, we are buildind the architecture of the chatbot.
//



---Basics knowledge about Tensorflow ----
1.In tf all variables are used in tensors.
2.Tensors are like an advanced arrays , more advanced than the numpy array, which are of single type.
3. It allows the fastest computation in the deep neural networks.
--PLACEHOLDERS--
All the variables used in tensors must be defined in what we call placeholders. Placeholders are like an advnced data structue that can 
many tensors.

//This function creates a placeholder for the inputs and the targets for any deep neural network
//This function takes in an input and output and for each of them it creates placeholders.
// The keep_prob placeholder is  a parameter that is used to control the dropout rate.
//DROPOUT RATE--- It is the rate of the neurons you choose to override during one iteration in the training. Usually 20, so tha twe deac
you deativate the training rate by 20%

def model_inputs():
  inputs = tf.placeholder(tf.int32,[None, None],name = 'input') //type of the data//dimensions of the matrix of the input data (2-d)//name of the data
  targets = tf.placeholder(tf.int32,[None, None],name = 'target')
  lr = tf.placeholder(tf.float32,name = 'learnin_rate')
  keep_prob = tf.placeholder(tf.int32,[None, None],name = 'keep_prob')
  return inputs, targets, lr, keep_prob
  
  //Preprocessing the targets
  //WHY-- because the decoder will only accept a certain format of the targets. The decoder gets to the targets and in order for 
  // for the targets to be accepted by the neural network, we need a special format.
  //This format is two- fold,The target must be into batches. The RNN doesn't accept single answers.
  For example the RNN will not take a single answer list, but will take the answers in a batch of size for example 10
  // Therefore we do two things, creating batches and adding and SOS for each answer list.Each target eill start eith SOS
  
def preprocess_targets(targets//inputs, word2int // this dic maps tokens to integers , batch_size):
    left_side = tf.fill([batch_size, 1], word2int['<SOS>']) // fill is used to fill the sos tokens with arguements == dimensions of the mateix
    right_side = tf.strided_slice(targets, [0,0], [batch_size, -1], [1,1]) // the right side contains all the tokens except the last one as for a decoder we don't need a EOS, stride lets to take a part of the input
    preprocessed_targets = tf.concat([left_side, right_side], 1)
    return preprocessed_targets
    
    // Now we create the architecture of the seq2seq model ie first encoder RNN layer
    //and also create the architecture of the decoder RNN layer
    
    def encoder_rnn(rnn_inputs, rnn_size, num_layers, keep_prob, sequence_length): //sequence length is the length of the question in each batch.
    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size) //creating an object of lstm cell class
    lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)// lstm with dropout applied
    encoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_dropout] * num_layers) // we make number of layers to make the encoder cell, it is composed of severel lstm cells
    encoder_output, encoder_state = tf.nn.bidirectional_dynamic_rnn(cell_fw = encoder_cell, 
                                                                    cell_bw = encoder_cell,
                                                                    sequence_length = sequence_length,
                                                                    inputs = rnn_inputs,
                                                                    dtype = tf.float32)
    return encoder_state

//We are only concerned with the encoder state which goes as an input to the decoder state. and what we need from a decoder is the decoder output.

//We need to decoding the training set.
//EMBEDDING -- it is a mapping from a word to a vectors of real number , each encoding uniquely

# Decoding the training set
def decode_training_set(encoder_state //the input to the decoder state, decoder_cell//cell in the RNN of the decoder, decoder_embedded_input// input on which we apply embedding, sequence_length, decoding_scope//an advanced datastructure that will wrap tensorflow variables, output_function //function used to return the decoder outputs in the end, keep_prob, batch_size):
    attention_states = tf.zeros([batch_size, 1// #colums, decoder_cell.output_size]) //3d matrices containing only 0s
    attention_keys //keys to be compared to the target state, attention_values //values used to construct the context vectors .Contxt is returned by encoder and used by decoder as first element of decoding , attention_score_function// similarity bw keys and target states, attention_construct_function// used to build the attention state = tf.contrib.seq2seq.prepare_attention (attention_states, attention_option = "bahdanau", num_units = decoder_cell.output_size)
    training_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_train(encoder_state[0]//from previous function,  //function taht will decode the training state
                                                                              attention_keys,
                                                                              attention_values,
                                                                              attention_score_function,
                                                                              attention_construct_function,
                                                                              name = "attn_dec_train"// name scope for the decoder)
    decoder_output, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,
                                                                                                               training_decoder_function,
                                                                                                              decoder_embedded_input,
                                                                                                              sequence_length,
                                                                                                              scope = decoding_scope)
    decoder_output_dropout = tf.nn.dropout(decoder_output, keep_prob) // decoder data with dropout applied
    return output_function(decoder_output_dropout)
    
    # now we need to perform the decoding for the test / validation set.// to improve the accuracy
    //Attention variables are most important to forward propogate the signals
    def decode_test_set(encoder_state, decoder_cell, decoder_embeddings_matrix, sos_id, eos_id, maximum_length, num_words, decoding_scope, output_function, keep_prob, batch_size):
    attention_states = tf.zeros([batch_size, 1, decoder_cell.output_size])
    attention_keys, attention_values, attention_score_function, attention_construct_function = tf.contrib.seq2seq.prepare_attention(attention_states, attention_option = "bahdanau", num_units = decoder_cell.output_size)
    test_decoder_function = tf.contrib.seq2seq.attention_decoder_fn_inference// cause after training we need to infer the answers for new qustions(output_function,
                                                                              encoder_state[0],
                                                                              attention_keys,
                                                                              attention_values,
                                                                              attention_score_function,
                                                                              attention_construct_function,
                                                                              decoder_embeddings_matrix,
                                                                              sos_id,
                                                                              eos_id,
                                                                              maximum_length,
                                                                              num_words,
                                                                              name = "attn_dec_inf")
    test_predictions, decoder_final_state, decoder_final_context_state = tf.contrib.seq2seq.dynamic_rnn_decoder(decoder_cell,
                                                                                                                test_decoder_function,
                                                                                                                scope = decoding_scope)
    return test_predictions
    
    
    /now we need to create the RNN of the decoder
    
    # Creating the Decoder RNN
def decoder_rnn(decoder_embedded_input, decoder_embeddings_matrix, encoder_state, num_words, sequence_length, rnn_size, num_layers, word2int, keep_prob, batch_size):
    with tf.variable_scope("decoding") as decoding_scope:
        lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)
        lstm_dropout = tf.contrib.rnn.DropoutWrapper(lstm, input_keep_prob = keep_prob)
        decoder_cell = tf.contrib.rnn.MultiRNNCell([lstm_dropout] * num_layers)
        weights = tf.truncated_normal_initializer(stddev = 0.1) //weights will be associated to the neurons
        biases = tf.zeros_initializer()
        output_function = lambda x: tf.contrib.layers.fully_connected(x,
                                                                      num_words,
                                                                      None,
                                                                      scope = decoding_scope,
                                                                      weights_initializer = weights,
                                                                      biases_initializer = biases)
        training_predictions = decode_training_set(encoder_state,
                                                   decoder_cell,
                                                   decoder_embedded_input,
                                                   sequence_length,
                                                   decoding_scope,
                                                   output_function,
                                                   keep_prob,
                                                   batch_size)
        decoding_scope.reuse_variables()
        test_predictions = decode_test_set(encoder_state,
                                           decoder_cell,
                                           decoder_embeddings_matrix,
                                           word2int['<SOS>'],
                                           word2int['<EOS>'],
                                           sequence_length - 1,
                                           num_words,
                                           decoding_scope,
                                           output_function,
                                           keep_prob,
                                           batch_size)
    return training_predictions, test_predictions

  // building the final seq2seqmodel,where we ensembl the encoder_rnn and decoder_rnn, this function returns the training predictions and the text predictions.
  
  def seq2seq_model(inputs, targets, keep_prob, batch_size, sequence_length, answers_num_words, questions_num_words, encoder_embedding_size, decoder_embedding_size, rnn_size, num_layers, questionswords2int):
    encoder_embedded_input = tf.contrib.layers.embed_sequence(inputs,
                                                              answers_num_words + 1,
                                                              encoder_embedding_size,
                                                              initializer = tf.random_uniform_initializer(0, 1))
    encoder_state = encoder_rnn(encoder_embedded_input, rnn_size, num_layers, keep_prob, sequence_length) //outut of the encoder and the input to the decoder
    preprocessed_targets = preprocess_targets(targets, questionswords2int, batch_size) //used to backpropagate the loss later in the decoding mechanism
    decoder_embeddings_matrix = tf.Variable(tf.random_uniform([questions_num_words + 1, decoder_embedding_size], 0, 1))
    decoder_embedded_input = tf.nn.embedding_lookup(decoder_embeddings_matrix, preprocessed_targets)
    training_predictions, test_predictions = decoder_rnn(decoder_embedded_input,
                                                         decoder_embeddings_matrix,
                                                         encoder_state,
                                                         questions_num_words,
                                                         sequence_length,
                                                         rnn_size,
                                                         num_layers,
                                                         questionswords2int,
                                                         keep_prob,
                                                         batch_size)
    return training_predictions, test_predictions
 
  //END OF BUIDING THE SEQ@SEQ MODEL
